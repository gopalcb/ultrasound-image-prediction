{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Get current/root directory\n",
    "root = os.getcwd()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas_profiling\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# figure size in inches\n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter settings\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "class_arr = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 61, 43, 11, 39, 82, 58, 18, 49, 42, 91, 97, 23, 29, 65, 15, 28, 31, 77, 56]\n"
     ]
    }
   ],
   "source": [
    "# Random data set select\n",
    "patients_index = []\n",
    "select_patients = 20\n",
    "\n",
    "train_items = []\n",
    "test_items = []\n",
    "\n",
    "last_index = 0\n",
    "\n",
    "for i in range(1, 101):\n",
    "    if i != 57 and i != 112 and i != 179 and i != 184 and i != 120:\n",
    "        patients_index.append(i)\n",
    "\n",
    "sampled_list = random.sample(patients_index, select_patients)\n",
    "\n",
    "for i in range(0, int(len(sampled_list)/2)):\n",
    "    train_items.append(sampled_list[i])\n",
    "    last_index = i\n",
    "\n",
    "for i in range(i+1, len(sampled_list)):\n",
    "    test_items.append(sampled_list[i])\n",
    "\n",
    "print(sampled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "4042\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Veriables\n",
    "feature_map = []\n",
    "classes = [] # Catheter: 1, Echo: 0\n",
    "data_count = 0\n",
    "file_count = 0\n",
    "\n",
    "mags = []\n",
    "phases = []\n",
    "sectors = []\n",
    "distances = []\n",
    "sigs = []\n",
    "\n",
    "cat_data = []\n",
    "echo_data = []\n",
    "\n",
    "# Read train data\n",
    "train_loc = 'D:/SCA/256_256/feature_map/exp/train'\n",
    "train_files = [f for f in listdir(train_loc) if isfile(join(train_loc, f))]\n",
    "\n",
    "print('Loading train data...')\n",
    "\n",
    "for file in train_files:\n",
    "    \n",
    "    f_arr = file.split('_')\n",
    "    pn = int(f_arr[0])\n",
    "    otype = f_arr[3]\n",
    "    \n",
    "    if pn in train_items:\n",
    "\n",
    "        lbl = 1 if otype == 'c' else 0\n",
    "\n",
    "        dataset=pd.read_csv(train_loc + '/' + file, header=None, delimiter='\\t')   \n",
    "        dataset = dataset.values\n",
    "\n",
    "        one_object_features = []\n",
    "\n",
    "        d_count = 0\n",
    "\n",
    "        for ds in dataset:\n",
    "            # Order: magnitude(0), phase(1), signature(2), sector(3), distance(4)\n",
    "            if d_count <= 39:\n",
    "\n",
    "                o_arr = ds[0].split(',')\n",
    "                o_arr = np.array(o_arr)\n",
    "                o_arr = o_arr.astype(np.float)\n",
    "\n",
    "                mags.append(o_arr[0])\n",
    "                phases.append(o_arr[1])\n",
    "                sectors.append(o_arr[3])\n",
    "                distances.append(o_arr[4])\n",
    "                sigs.append(o_arr[2])\n",
    "\n",
    "                #one_object_features.append(o_arr[0])\n",
    "                #one_object_features.append(o_arr[1])\n",
    "                one_object_features.append(o_arr[2])\n",
    "                #one_object_features.append(o_arr[3])\n",
    "                #one_object_features.append(o_arr[4])\n",
    "\n",
    "                d_count += 1\n",
    "\n",
    "                if d_count == 39:\n",
    "                    continue\n",
    "\n",
    "\n",
    "        one_object_features = np.array(one_object_features)\n",
    "\n",
    "        # Data normalization\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(one_object_features.reshape(-1, 1))\n",
    "\n",
    "        feature_map.append(scaled_data)\n",
    "        classes.append(lbl)\n",
    "\n",
    "        if lbl == 1:\n",
    "            cat_data.append(scaled_data)\n",
    "            echo_data.append(scaled_data)\n",
    "        else:\n",
    "            echo_data.append(scaled_data)\n",
    "\n",
    "        data_count = data_count + 1\n",
    "        print('\\r' + str(data_count), end='')\n",
    "\n",
    "        file_count += 1\n",
    "    \n",
    "feature_map = np.array(feature_map)\n",
    "classes = np.array(classes)\n",
    "\n",
    "print('\\nDone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "4011\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "\n",
    "# Veriables\n",
    "test_feature_map = []\n",
    "test_classes = [] # Catheter: 1, Echo: 0\n",
    "test_files_title = []\n",
    "data_count = 0\n",
    "\n",
    "# Read test data\n",
    "test_loc = 'D:/SCA/256_256/feature_map/exp/train'\n",
    "#test_loc = 'D:/SCA/256_256/feature_map/test_unet'\n",
    "test_files = [f for f in listdir(test_loc) if isfile(join(test_loc, f))]\n",
    "\n",
    "print('Loading test data...')\n",
    "\n",
    "for file in test_files:\n",
    "    f_arr = file.split('_')\n",
    "    pn = int(f_arr[0])\n",
    "    otype = f_arr[3]\n",
    "    \n",
    "    if pn in test_items:\n",
    "        \n",
    "        if otype == 'e' or otype == 'c':\n",
    "    \n",
    "            lbl = 1 if otype == 'c' else 0\n",
    "\n",
    "            dataset=pd.read_csv(test_loc + '/' + file, header=None, delimiter='\\t')   \n",
    "            dataset = dataset.values\n",
    "            if len(dataset) == 0:\n",
    "                print('null')\n",
    "\n",
    "            one_object_features = []\n",
    "            d_count = 0\n",
    "\n",
    "            for ds in dataset:\n",
    "                # Order: magnitude(0), phase(1), signature(2), sector(3), distance(4)\n",
    "\n",
    "                if d_count <= 39:\n",
    "                    o_arr = ds[0].split(',')\n",
    "                    o_arr = np.array(o_arr)\n",
    "                    o_arr = o_arr.astype(np.float)\n",
    "\n",
    "                    #one_object_features.append(o_arr[0])\n",
    "                    #one_object_features.append(o_arr[1])\n",
    "                    one_object_features.append(o_arr[2])\n",
    "                    #one_object_features.append(o_arr[3])\n",
    "                    #one_object_features.append(o_arr[4])\n",
    "\n",
    "                    d_count += 1\n",
    "\n",
    "                    if d_count == 39:\n",
    "                        continue\n",
    "\n",
    "            data_count = data_count + 1\n",
    "            print('\\r' + str(data_count), end='')\n",
    "\n",
    "            one_object_features = np.array(one_object_features)\n",
    "\n",
    "            # Data normalization\n",
    "            scaler = StandardScaler()\n",
    "            scaled_data = scaler.fit_transform(one_object_features.reshape(-1, 1))\n",
    "\n",
    "            test_feature_map.append(scaled_data)\n",
    "            test_classes.append(lbl)\n",
    "            test_files_title.append(file)\n",
    "    \n",
    "test_feature_map = np.array(test_feature_map)\n",
    "test_classes = np.array(test_classes)\n",
    "test_files_title = np.array(test_files_title)\n",
    "\n",
    "print('\\nDone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape train data set array into a 2d array.\n",
    "nsamples, nx, ny = feature_map.shape\n",
    "d2_train_dataset = feature_map.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape test data set array into a 2d array.\n",
    "nsamples_, nx_, ny_ = test_feature_map.shape\n",
    "d2_test_dataset = test_feature_map.reshape((nsamples_,nx_*ny_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the classifier\n",
    "classifier = RandomForestClassifier(n_estimators=800)\n",
    "\n",
    "# Train the model using the training sets\n",
    "classifier.fit(d2_train_dataset, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictin on the test set\n",
    "y_pred = classifier.predict(d2_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7354774370481176\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model Accuracy\n",
    "acc = accuracy_score(test_classes, y_pred)\n",
    "acc_arr.append(acc)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7385239929218278,\n",
       " 0.762008495806557,\n",
       " 0.7108669108669109,\n",
       " 0.7519202823334026,\n",
       " 0.7226019325948622]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_arr = [0.7385239929218278, 0.762008495806557, 0.7108669108669109, 0.7519202823334026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
